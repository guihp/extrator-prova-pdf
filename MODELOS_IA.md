# ğŸ¤– Modelos de IA Utilizados

## ğŸ“Š Modelos Configurados

### Gemini (Google)

**Ordem de PreferÃªncia (tentativa automÃ¡tica):**
1. `gemini-2.0-flash-exp` - Mais recente (experimental, mais rÃ¡pido)
2. `gemini-1.5-pro` - Mais poderoso e estÃ¡vel (recomendado para qualidade)
3. `gemini-1.5-flash` - Mais rÃ¡pido (boa qualidade)
4. `gemini-1.0-pro` - Fallback estÃ¡vel
5. `gemini-pro` - Ãšltimo fallback

**CaracterÃ­sticas:**
- âœ… Suporta atÃ© 1M tokens (Gemini 1.5+)
- âœ… Melhor para anÃ¡lise de documentos longos
- âœ… Excelente para processamento de imagens
- âœ… Gratuito com limites generosos

**Uso no Sistema:**
- AnÃ¡lise estrutural de provas
- Mapeamento de imagens Ã s questÃµes
- IdentificaÃ§Ã£o de questÃµes numeradas

### OpenAI (ChatGPT)

**Ordem de PreferÃªncia (detecÃ§Ã£o automÃ¡tica):**
1. `gpt-4o` - Mais recente e melhor (recomendado)
   - âœ… Suporta JSON mode (`response_format`)
   - âœ… Melhor qualidade de extraÃ§Ã£o
   - âœ… Mais rÃ¡pido que gpt-4
   
2. `gpt-4-turbo` - VersÃ£o turbo
   - âœ… Suporta JSON mode
   - âœ… Boa qualidade
   
3. `gpt-4` - Fallback
   - âŒ NÃ£o suporta JSON mode
   - âœ… Boa qualidade
   
4. `gpt-3.5-turbo` - Ãšltimo fallback
   - âœ… Suporta JSON mode
   - âš ï¸ Qualidade menor

**CaracterÃ­sticas:**
- âœ… JSON Mode disponÃ­vel (gpt-4o, gpt-4-turbo, gpt-3.5-turbo)
- âœ… Garante JSON vÃ¡lido quando suportado
- âœ… Excelente para extraÃ§Ã£o estruturada

**Uso no Sistema:**
- ExtraÃ§Ã£o de questÃµes (mÃºltiplas estratÃ©gias)
- ValidaÃ§Ã£o e refinamento de questÃµes
- Fallback quando Gemini nÃ£o estÃ¡ disponÃ­vel

## ğŸ”„ DetecÃ§Ã£o AutomÃ¡tica

O sistema detecta automaticamente:
1. **Melhor modelo Gemini disponÃ­vel** - Tenta modelos mais recentes primeiro
2. **Melhor modelo OpenAI disponÃ­vel** - Testa disponibilidade e suporta JSON mode
3. **Fallback automÃ¡tico** - Se um modelo falhar, tenta o prÃ³ximo

## ğŸ“ˆ Melhorias com Modelos Recentes

### Gemini 2.0 / 1.5 Pro:
- âœ… Melhor compreensÃ£o de contexto
- âœ… Melhor processamento de imagens
- âœ… Suporte a documentos muito longos
- âœ… Respostas mais precisas

### GPT-4o:
- âœ… JSON Mode (garante JSON vÃ¡lido)
- âœ… Melhor qualidade de extraÃ§Ã£o
- âœ… Menos erros de parsing
- âœ… Respostas mais consistentes

## âš™ï¸ ConfiguraÃ§Ã£o

Os modelos sÃ£o configurados automaticamente no `__init__` do `AIAnalyzer`:

```python
# Gemini: Tenta modelos mais recentes primeiro
model_names = [
    'gemini-2.0-flash-exp',  # Mais recente
    'gemini-1.5-pro',        # Mais poderoso
    'gemini-1.5-flash',      # Mais rÃ¡pido
    'gemini-1.0-pro',        # Fallback
    'gemini-pro'             # Ãšltimo fallback
]

# OpenAI: Detecta melhor modelo disponÃ­vel
openai_models = [
    'gpt-4o',           # Mais recente (JSON mode âœ…)
    'gpt-4-turbo',      # Turbo (JSON mode âœ…)
    'gpt-4',            # Fallback (JSON mode âŒ)
    'gpt-3.5-turbo'     # Ãšltimo fallback (JSON mode âœ…)
]
```

## ğŸ¯ RecomendaÃ§Ãµes

### Para Melhor Qualidade:
- **Gemini:** `gemini-1.5-pro` (mais estÃ¡vel e poderoso)
- **OpenAI:** `gpt-4o` (melhor qualidade + JSON mode)

### Para Melhor Performance:
- **Gemini:** `gemini-1.5-flash` ou `gemini-2.0-flash-exp` (mais rÃ¡pido)
- **OpenAI:** `gpt-4o` (rÃ¡pido e de alta qualidade)

### Para Economia:
- **Gemini:** Qualquer versÃ£o (todas tÃªm limites generosos)
- **OpenAI:** `gpt-3.5-turbo` (mais barato, ainda suporta JSON mode)

## ğŸ“ Notas

- O sistema tenta automaticamente os modelos mais recentes
- Se um modelo nÃ£o estiver disponÃ­vel, usa o prÃ³ximo da lista
- JSON mode Ã© usado automaticamente quando suportado (garante JSON vÃ¡lido)
- Logs mostram qual modelo foi configurado na inicializaÃ§Ã£o




